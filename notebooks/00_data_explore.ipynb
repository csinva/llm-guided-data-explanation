{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import imodels\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression, Ridge, Lasso, RidgeCV, ElasticNetCV, LinearRegression, LassoCV\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a linear regression problem\n",
    "Groundtruth is fit to the entire dataset (selected via CV) whereas the other models are fit to a small subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_GRID_LINEAR_REGRESSION = [\n",
    "    {\n",
    "        \"est\": [\n",
    "            RidgeCV(), ElasticNetCV(), LinearRegression(), LassoCV()\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# DSETS_CLASSIFICATION = ['pima_diabetes']\n",
    "# X, y, feature_names = imodels.get_clean_dataset(\"pima_diabetes\")\n",
    "X, y, feature_names = imodels.get_clean_dataset(\"california_housing\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.99\n",
    ")\n",
    "\n",
    "# preprocess gt data\n",
    "X = sklearn.preprocessing.StandardScaler().fit_transform(X)\n",
    "y = sklearn.preprocessing.StandardScaler().fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# preprocess split data\n",
    "trans = sklearn.preprocessing.StandardScaler()\n",
    "X_train = trans.fit_transform(X_train)\n",
    "X_test = trans.transform(X_test)\n",
    "transy = sklearn.preprocessing.StandardScaler()\n",
    "y_train = transy.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test = transy.transform(y_test.reshape(-1, 1)).flatten()\n",
    "print(\"shapes\", X.shape, y.shape, \"nunique\",\n",
    "      np.unique(y).size, '-> train', X_train.shape)\n",
    "\n",
    "\n",
    "def fit_and_get_feats(X_train, y_train, topk=2):\n",
    "    m = imodels.AutoInterpretableRegressor(\n",
    "        # m = imodels.AutoInterpretableClassifier(\n",
    "        param_grid=PARAM_GRID_LINEAR_REGRESSION, refit=True)\n",
    "    m.fit(X_train, y_train, cv=3)\n",
    "\n",
    "    # print(\"best params\", m.est_.best_params_)\n",
    "    # print(\"best score\", m.est_.best_score_)\n",
    "    # print(\"best estimator\", m.est_.best_estimator_)\n",
    "    # print(\"best estimator params\", m.est_.best_estimator_.get_params())\n",
    "    # print('selected from', m.param_grid)\n",
    "    df = pd.DataFrame(m.est_.cv_results_).sort_values(\n",
    "        \"rank_test_score\").reset_index()\n",
    "    first_cols = [\"rank_test_score\", \"mean_test_score\", \"std_test_score\"]\n",
    "    df = df[first_cols +\n",
    "            [c for c in df.columns if c not in first_cols]].round(3)\n",
    "    # remove std_ cols\n",
    "    df = df[[c for c in df.columns if \"std_\" not in c]]\n",
    "\n",
    "    # Refit top models with best params\n",
    "    d = defaultdict(list)\n",
    "    for i in range(topk):\n",
    "        params = df.loc[i, 'params']\n",
    "        clf = m.est_.best_estimator_.set_params(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        clf = clf.steps[0][1]\n",
    "        d['model'].append(deepcopy(clf))\n",
    "        d['train_score'].append(clf.score(X_train, y_train))\n",
    "        d['test_score'].append(clf.score(X_test, y_test))\n",
    "        d['coef'].append(clf.coef_)\n",
    "        d['intercept'].append(clf.intercept_)\n",
    "    d = pd.DataFrame(d)\n",
    "    return d\n",
    "\n",
    "\n",
    "d_gt = fit_and_get_feats(X, y, topk=1)\n",
    "d_small = fit_and_get_feats(X_train, y_train, topk=2)\n",
    "d = pd.concat((d_gt, d_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Note: these our coefficients after standardizing the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'feature_names': feature_names + ['Intercept']}\n",
    "for i in range(len(d)):\n",
    "    coef = d.iloc[i].coef.tolist() + \\\n",
    "        [d.iloc[i].intercept.tolist()]\n",
    "    if i == 0:\n",
    "        out['GT'] = coef\n",
    "    else:\n",
    "        out[f'{str(d.iloc[i][\"model\"])[:-4]} ({i})'] = coef\n",
    "\n",
    "coefs = pd.DataFrame.from_dict(out)\n",
    "col1 = coefs.columns[1]\n",
    "coefs = coefs.sort_values(by=col1)\n",
    "vabs = np.max(np.abs(coefs[col1]))\n",
    "\n",
    "display(d.round(3).drop(\n",
    "    columns=['coef', 'intercept']))\n",
    "display(\n",
    "    coefs\n",
    "    .style.background_gradient(\n",
    "        cmap=sns.diverging_palette(\n",
    "            20, 220, as_cmap=True, center='dark'),\n",
    "        vmin=-vabs, vmax=vabs\n",
    "    )\n",
    "    .format(precision=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's ask GPT some questions about the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to a chat model like GPT-4 or Vicuna\n",
    "gpt4 = guidance.llms.OpenAI(\"gpt-4-0314\")\n",
    "# vicuna = guidance.llms.transformers.Vicuna(\"your_path/vicuna_13B\", device_map=\"auto\")\n",
    "\n",
    "experts = guidance('''\n",
    "{{#system~}}\n",
    "You are a helpful and terse assistant.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "I want a response to the following question:\n",
    "{{query}}\n",
    "Name 3 world-class experts (past or present) who would be great at answering this?\n",
    "Don't answer the question yet.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'expert_names' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Great, now please answer the question as if these experts had collaborated in writing a joint anonymous answer.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'answer' temperature=0 max_tokens=500}}\n",
    "{{~/assistant}}\n",
    "''', llm=gpt4)\n",
    "\n",
    "experts(query='How can I be more productive?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
